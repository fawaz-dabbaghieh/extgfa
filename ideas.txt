The idea now is to do the following:
  1- Read the GFA completely and generate networkx object  (done)
  2- Run the Kernighan-Lin algorithm on the graph  (done)
  3- Separate the components, and depending on the number of components
     - Merge the smallest components with the others  (kinda done)
     - Rerun KL on the big components and run merge, but only keep a small number of components, depending on some
       threshold
  4- Output this partitioning into some simple data structure, probably a dict with node_id:chunk_id
  5- Once I have this node_id:chunk_id, I can generate a new GFA file with my Graph class
     - Take this graph, add the chunk id to the ndoes and then output based on the chunk and keep record of line
       offsets for an offset index.
     - Also add the chunk ID to the L lines tags
  6- What is left then is to edit the old ChGraph to use the offset index to load and unload chunks, and voila!!!